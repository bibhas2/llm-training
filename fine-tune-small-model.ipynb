{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124f0101-4931-4841-98a1-270d1347c766",
   "metadata": {},
   "source": [
    "# Fine-tune a Small Transformer Model\n",
    "A purpose built small model that is fine-tuned for the job can be cheaper and faster than using a LLM.\n",
    "\n",
    "Due to the small size, we can train the entire model (all the weights) in a relatively small machine.\n",
    "\n",
    "In this notebook we will train a tiny model called DistilBERT to classify the sentiment of text to either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a444fd-d66e-4ec2-85ff-39bf55f4731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70bebe-c7a0-4112-939f-c4a677988fad",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "We will use the [IMDB](https://huggingface.co/datasets/stanfordnlp/imdb) dataset. It provides movie review text labelled as either positive (1) or negative (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf14893-55fd-49b2-bcbe-9d44331c27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07e19ca-50aa-4646-ba53-90239e00d533",
   "metadata": {},
   "source": [
    "## Inspect the Dataset\n",
    "Each sample looks something like this.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"text\": \"I loved the movie.\",\n",
    "  \"label\": 1\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9431bfc-cd2a-491e-ac3c-53e5fe5e7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63247b-bf53-4962-b9f7-471e2a1e20f5",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "For training, the text data needs to be tokenized. We will do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a564c1d-5ad8-4649-b344-398cfdfcfa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf933d-1e31-4457-990b-67544373fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    #Truncate to the maximum number of tokens accepted by the model\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb1638-a62f-436f-b077-833178a5b206",
   "metadata": {},
   "source": [
    "This mapping will add the token IDs as ``input_ids`` and ``attention_mask`` features for each sample. These names are significant. The model knows to look for these features in the forward pass. The ``text`` feature is not used by the model and will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511feb8c-41a5-44e0-a150-fee0f82f793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ee89b-3a39-40da-9730-342aa8c76f9d",
   "metadata": {},
   "source": [
    "## Load the Base Model\n",
    "Since we plan to tune the base model for a classfication task, we should load it using ``AutoModelForSequenceClassification``. We need to carefully supply the number of possible classes using ``num_labels``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbe8a7-1b62-43a9-8214-98a24416279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name, \n",
    "    num_labels=2,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dac97-623b-4c9f-84d8-be26397a5178",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59699dc2-956e-4bc2-aa87-93c80dcba233",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sentiment-classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13060fe-f5d8-4d22-ac7d-1c6a26a6b729",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e13b35-8e5e-4b8f-a6be-b2a77a9e99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8a53a-b4b2-4467-9812-ff45824674ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unload models to save memory\n",
    "del base_model\n",
    "del tokenizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be173887-f082-47c1-8bad-437c2c75a73b",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181829ad-bc70-434b-a39c-45b9f7d86faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(model, tokenizer, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    #Run inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    #Get the predicted class with the highest probability\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "\n",
    "    print(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca498e1e-368a-4059-8c0f-e68d3bf620cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the trained model\n",
    "model_name = \"./sentiment-classifier\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e26b8a-f6c0-4fc0-9a78-8d4ebfbb2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_sentiment(model, tokenizer, \"The movie was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d7fee-c3f1-4afd-8e71-b66c764b8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_sentiment(model, tokenizer, \"The food was terrible!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fb728-5d0a-4e3f-b691-76d1eb743e63",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook we did a full training of a small transformer model called DistillBERT. The model was trained to learn how to classify the sentiment of a text as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58400906-1de1-42fb-ac6e-58846cee4c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
